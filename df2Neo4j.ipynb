{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed011030",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community langchain-experimental gradio neo4j pandas requests\n",
    "!pip install -U langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff97ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ast\n",
    "import re\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import (to_hetero, GraphConv, GATConv, GCNConv, SAGEConv, GATv2Conv, Linear, HeteroConv, HGTConv, RGCNConv, RGATConv, MessagePassing, global_add_pool)\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.explain import GNNExplainer\n",
    "import torch_geometric\n",
    "import pyg_lib\n",
    "import torch_sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import networkx as nx",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"PyG Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b300548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set seed for reproducibility\n",
    "def set_seed(seed_value=24):\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    torch.cuda.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ca9d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neo4j+s://5f5434fc.databases.neo4j.io\n"
     ]
    }
   ],
   "source": [
    "PTH = os.getenv(\"PTH\")\n",
    "\n",
    "x = os.getenv(\"user_profile\")\n",
    "\n",
    "# bartala\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI_\"+x)\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD_\"+x)\n",
    "\n",
    "print(NEO4J_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3aaaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url = NEO4J_URI,\n",
    "    username = NEO4J_USERNAME,\n",
    "    password = NEO4J_PASSWORD,\n",
    "    database = NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40805f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "graph.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_document IF NOT EXISTS\n",
    "FOR (d:Document) REQUIRE d.id IS UNIQUE\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "graph.query(\"\"\"\n",
    "CREATE VECTOR INDEX document_embedding_index IF NOT EXISTS\n",
    "FOR (d:Document) ON (d.textEmbedding)\n",
    "OPTIONS {\n",
    "  indexConfig: {\n",
    "    `vector.dimensions`: 1536,\n",
    "    `vector.similarity_function`: 'cosine'\n",
    "  }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab14a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into DataFrame\n",
    "df = pd.read_csv(os.path.join(PTH,'AIVI_HI.csv'))\n",
    "df['id'] = range(1, len(df) + 1)\n",
    "df = df[df['posts.comments.text'].notna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d7ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comments = df[df['text.comments.text'].notna()].copy()\n",
    "user_comments.loc[:, 'user_or_influencer'] = 'USER'\n",
    "\n",
    "influencers_posts = df[df['posts.comments.text'].notna() & df['text.comments.text'].isna()].copy()\n",
    "influencers_posts.loc[:, 'user_or_influencer'] = 'INFLUENCER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc65216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_comments = user_comments[['id', \n",
    "                                        'PROFILE.url',\n",
    "                                        'user_type',\n",
    "                                        'pot.comment.likes_count', \n",
    "                                        'posts.time',\n",
    "                                        'posts.comments.user', \n",
    "                                        'text.comments.text',\n",
    "                                        'user_or_influencer',                                       \n",
    "                                        ]]\n",
    "\n",
    "user_comments.columns = ['id',\n",
    "                        'PROFILE.url',\n",
    "                       'user_type',\n",
    "                       'likes_count', \n",
    "                       'posting_time',\n",
    "                       'posting_user', \n",
    "                       'text',\n",
    "                       'user_or_influencer']\n",
    "\n",
    "\n",
    "influencers_posts = influencers_posts[['id', \n",
    "                                         'PROFILE.url',\n",
    "                                        'user_type',\n",
    "                                        'posts.likes_count', \n",
    "                                        'posts.time',\n",
    "                                        'posts.comments.user', \n",
    "                                        'posts.comments.text', \n",
    "                                        'user_or_influencer',                                       \n",
    "                                        ]]\n",
    "\n",
    "influencers_posts.columns = ['id',\n",
    "                        'PROFILE.url',\n",
    "                       'user_type',\n",
    "                       'likes_count', \n",
    "                       'posting_time',\n",
    "                       'posting_user', \n",
    "                       'text',\n",
    "                       'user_or_influencer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two DataFrames and ignore column names to avoid conflicts\n",
    "combined_df = pd.concat([user_comments, influencers_posts], ignore_index=True)\n",
    "\n",
    "# Remove rows with missing or empty text\n",
    "combined_df = combined_df[combined_df['text'].notna() & (combined_df['text'].str.strip() != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for index, row in combined_df.iterrows():\n",
    "    doc = Document(\n",
    "      page_content= row['text'],\n",
    "      metadata={\n",
    "           'id' : row['id'],\n",
    "           'user_type' : row['user_type'],\n",
    "           'likes_count' : row['likes_count'],\n",
    "           'posting_time' : row['posting_time'],\n",
    "           'posting_user' : row['posting_user'],\n",
    "           'user_or_influencer' : row['user_or_influencer']\n",
    "      }\n",
    "    )\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfe2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_llm_input(documents):\n",
    "    for doc in documents:\n",
    "        if isinstance(doc.page_content, str):\n",
    "            doc.page_content = doc.page_content.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1edb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# Prompt addition to enforce strict JSON output\n",
    "no_none_types = (\n",
    "    \"IMPORTANT INSTRUCTIONS:\\n\"\n",
    "    \"- Output must be a JSON array of flat dictionaries.\\n\"\n",
    "    \"- Each dictionary MUST contain: 'head', 'head_type', 'tail', 'tail_type', and 'relation'.\\n\"\n",
    "    \"- All values MUST be plain strings â€” no lists, dictionaries, or nested structures.\\n\"\n",
    "    \"- If a field includes multiple values, return only one OR split them into multiple triplets.\\n\"\n",
    "    \"- Use 'Entity' as the type if unknown.\\n\"\n",
    "    \"- DO NOT include comments or explanations.\\n\"\n",
    "    \"- DO NOT hallucinate facts or make up people/places not mentioned.\\n\"\n",
    "    \"- If the input contains only emojis, punctuation, or non-language symbols, return an empty list (`[]`) and nothing else.\\n\"\n",
    "    \"- Example:\\n\"\n",
    "    \"[{{\\\"head\\\": \\\"user\\\", \\\"head_type\\\": \\\"Person\\\", \\\"tail\\\": \\\"Bar-Ilan\\\", \\\"tail_type\\\": \\\"Organization\\\", \\\"relation\\\": \\\"affiliated_with\\\"}}]\"\n",
    ")\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[],\n",
    "    allowed_relationships=[],\n",
    "    additional_instructions=no_none_types\n",
    ")\n",
    "\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents[0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14122d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store graph documents in Neo4j\n",
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72bc407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# Create vector index and store embeddings in Neo4j for document nodes\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\",\n",
    "    url = NEO4J_URI,\n",
    "    username = NEO4J_USERNAME,\n",
    "    password = NEO4J_PASSWORD,\n",
    "    database = NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31fb4e",
   "metadata": {},
   "source": [
    "# Connect to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5181a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "import networkx as nx\n",
    "\n",
    "PTH = os.getenv(\"PTH\")\n",
    "\n",
    "x = os.getenv(\"user_profile\")\n",
    "\n",
    "# bartala\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI_\"+x)\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD_\"+x)\n",
    "\n",
    "print(NEO4J_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7258b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cypher query to get internal edges of the subgraph connected to HUMAN and AIVI influencers (Document nodes)\n",
    "\n",
    "cypher_query_HI = \"\"\"\n",
    "MATCH (d:Document {user_type: 'HUMAN'})\n",
    "WITH collect(d) AS docs\n",
    "UNWIND docs AS d\n",
    "MATCH (d)--(n)  // collect connected nodes\n",
    "WITH collect(DISTINCT d) + collect(DISTINCT n) AS S\n",
    "UNWIND S AS node\n",
    "MATCH (node)-[r]-(other)\n",
    "WHERE other IN S\n",
    "RETURN DISTINCT startNode(r).id AS source, endNode(r).id AS target, type(r) AS relation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cypher_query_AIVI = \"\"\"\n",
    "MATCH (d:Document {user_type: 'AI'})\n",
    "WITH collect(d) AS docs\n",
    "UNWIND docs AS d\n",
    "MATCH (d)--(n)  // collect connected nodes\n",
    "WITH collect(DISTINCT d) + collect(DISTINCT n) AS S\n",
    "UNWIND S AS node\n",
    "MATCH (node)-[r]-(other)\n",
    "WHERE other IN S\n",
    "RETURN DISTINCT startNode(r).id AS source, endNode(r).id AS target, type(r) AS relation\n",
    "\"\"\"\n",
    "\n",
    "# Function to extract data\n",
    "def extract_edgelist(uri, user, password, database, query):\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    with driver.session(database=database) as session:\n",
    "        results = session.execute_read(lambda tx: tx.run(query).data())\n",
    "    driver.close()\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run the extraction\n",
    "df_edgelist_HI = extract_edgelist(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, NEO4J_DATABASE, cypher_query_HI)\n",
    "\n",
    "df_edgelist_AIVI = extract_edgelist(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD, NEO4J_DATABASE, cypher_query_AIVI)\n",
    "\n",
    "# Save to CSV or display\n",
    "df_edgelist_HI.to_csv(os.path.join(PTH, \"HI_subgraph_edgelist.csv\"), index=False)\n",
    "df_edgelist_AIVI.to_csv(os.path.join(PTH, \"AIVI_subgraph_edgelist.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build NetworkX graph\n",
    "G_HI = nx.from_pandas_edgelist(df_edgelist_HI, source='source', target='target', edge_attr='relation', create_using=nx.DiGraph())\n",
    "\n",
    "# Basic summary\n",
    "print(f\"Graph has {G_HI.number_of_nodes()} nodes and {G_HI.number_of_edges()} edges.\")\n",
    "\n",
    "# Compute centrality\n",
    "degree_centrality = nx.degree_centrality(G_HI)\n",
    "betweenness = nx.betweenness_centrality(G_HI)\n",
    "\n",
    "# Convert to DataFrame\n",
    "centrality_df = pd.DataFrame({\n",
    "    \"node\": list(degree_centrality.keys()),\n",
    "    \"degree_centrality\": list(degree_centrality.values()),\n",
    "    \"betweenness\": [betweenness[n] for n in degree_centrality.keys()]\n",
    "})\n",
    "\n",
    "# Show top 10 by degree\n",
    "print(centrality_df.sort_values(by=\"degree_centrality\", ascending=False).head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
